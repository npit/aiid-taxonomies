[
  {
    "name": "Inadequate Data Sampling",
    "description": "Data sampling is misconfigured, in terms of resolution, selection, biases,  etc."
  },
  {
    "name": "Adversarial Data",
    "description": "Cases where the training dataset includes instances having unexpected content, labels or characteristics, willingly / maliciously misconfigured."
  },
  {
    "name": "Learning Dataset Imbalance",
    "description": "An AI system is set to learn from a collection of data that does not provide enough instances for all desired predictions (e.g. classes)."
  },
  {
    "name": "Poor Generalization",
    "description": "A trained AI system fails to perform well once deployed in the real world, where conditions (e.g. statistical properties of input data due to noise, environment, etc.) are novel and  considerably different from the training environment.",
    "children": [
      {
        "name": "Concept Drift",
        "description": "The phenomenon where a trained model exhibits poor generalization due to unaccounted-for changes in the statistical properties of input data and their relationship to the predicted quantity that emerge after time passes. "
      }
    ]
  },
  {
    "name": "Tuning Issues",
    "description": "Failures arise due to model configuration, tuning and case-specific details, rather than core capability / methodology-related limitations.",
    "children": [
      {
        "name": "Misconfigured Aggregation",
        "description": "The model's decision arises by considering multiple marginal predictions, the combination of which is skewed (e.g. under/overestimating contribution of a particular component) or otherwise problematic."
      },
      {
        "name": "Misconfigured Threshold",
        "description": "The model's decision threshold is configured to favor a subset of classes, leading in large performance differences in, e.g. precision and recall."
      }
    ]
  },
  {
    "name": "Underfitting",
    "description": "The model  adopted mantains assumptions via which it cannot capture complexity present in the data and generate accurate predictions."
  },
  {
    "name": "Underspecification",
    "description": "The system lacks fundamental and/or necessary components / functionalities to safely and effectively deal with the real-world task it is assigned to.",
    "children": [
      {
        "name": "Lack of Capability Control",
        "description": "The system is allowed to act in the real world with a impact / capability levels far beyond what its requires."
      },
      {
        "name": "Misaligned Objective",
        "description": "Failure outcomes are directly and heavily correlated to the most important task / domain requirements being ignored by the training objective."
      },
      {
        "name": "Unsafe Exposure or Access",
        "description": "The system lacks exposure / access limitations in a way that its outputs become harmful."
      },
      {
        "name": "Incomplete Data Attribute Capture",
        "description": "Information extraction from real-world instances omit attributes that are important to representing the instance and solving the learning problem effectively."
      },
      {
        "name": "Ignored Expected Externalities",
        "description": "A system's application results in unsurprising harmful externalities not considered or ignored by the designers and/or owners"
      }
    ]
  },
  {
    "name": "Distributional Bias",
    "description": "A trained model reflects biases that exist in its training data that are not representative to the real world or convey meaning that is context-specific and not generally applicable."
  },
  {
    "name": "Lack of Adversarial Robustness",
    "description": "The scenario where a model is sensitive to small changes to input data causing large, undesirable changes in its output."
  },
  {
    "name": "Lack of Transparency",
    "description": "The system converts input data into outputs without clearly exposing internal computational steps and procedures to outside observers. "
  }
]
